{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP2 - Aprendizaje Automático\n",
    "\n",
    "Francisco Javier Piqueras Martínez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos los imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow import keras\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos versiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset de MINST de keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_dataset = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos en nuestro train set y test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = MNIST_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primero separamos el validation set del training set y escalamos cada pixel al rango 0-1.\n",
    "\n",
    "Puesto que cada pixel toma un valor entre 0 y 255, vamos a dividir por 255. Dividimos por 255 como float (con el '.') para que el resultado. también tenga decimales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tenemos 60000 imágenes en matrices de 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[5], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación del modelo\n",
    "\n",
    "Vamos a intentar resolver el problema con una única MLP de 4 capas ocultas usando la Sequential API.\n",
    "Como se trata de un problema de Multiclass classification con matrices de 28x28 usaremos:\n",
    "- 28x28 = 784 input neurons\n",
    "- 4 capas opcultas\n",
    "- Neuronas por capa: 300\n",
    "- 10 output neurons (una por clase)\n",
    "- Función de activación de las capas ocultas: ReLU\n",
    "- Función de activación de la output layer: Softmax\n",
    "- Loss Function: Cross Entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_neurons = 300\n",
    "class_num = 10\n",
    "\n",
    "model1 = keras.models.Sequential()\n",
    "model1.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model1.add(keras.layers.Dense(hidden_neurons, activation=keras.activations.relu))\n",
    "model1.add(keras.layers.Dense(hidden_neurons, activation=keras.activations.relu))\n",
    "model1.add(keras.layers.Dense(hidden_neurons, activation=keras.activations.relu))\n",
    "model1.add(keras.layers.Dense(hidden_neurons, activation=keras.activations.relu))\n",
    "model1.add(keras.layers.Dense(class_num, activation=keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=\"sgd\", \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos el modelo\n",
    "\n",
    "Vamos a implementar Early Stopping y guardar el modelo con mejor rendimiento. También vamos a usar el callback de TensorBoard que propociona Keras para visualizar la curva de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un método que genere carpetas parametrizado por la fecha. Esto lo usará TB para giardar los logs de cada run en una carpeta distinta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"tb_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Para solucionar un problema en OSX: \n",
    "> Error: Initializing libiomp5.dylib, but found libiomp5.dylib already initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TB callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_cb = keras.callbacks.TensorBoard(get_run_logdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint callback para guardar el estado de los modelos en cada epoch.\n",
    "\n",
    "Guardamos sólo el mejor para ahorrar espacio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_cb = keras.callbacks.ModelCheckpoint(\"intento1_model.h5\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early Stop callback. Lo parametrizamos con 15 epoch de paciencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_cb = keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalmente entrenamos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model1.fit( X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[tb_cb, ck_cb, es_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos la extensión de TB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard\n",
    "%tensorboard --logdir=./tb_logs --port=6008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos un accuracy > 98%. Sin embargo, vamos a hacer hyperparameter tunning.\n",
    "\n",
    "## Hyperparameter Tunning\n",
    "\n",
    "Vamos a hcer un wrapper para nuestro modelo y que así podamos usar el RandomzedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.backend.clear_session()\n",
    "#np.random.seed(42)\n",
    "#tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=300, learning_rate=3e-3, input_shape=[28, 28]):\n",
    "    model = keras.models.Sequential()\n",
    "    # Input Layer\n",
    "    model.add(keras.layers.Flatten(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=keras.activations.relu))\n",
    "    # Output Layer\n",
    "    model.add(keras.layers.Dense(10, activation=keras.activations.softmax))\n",
    "    \n",
    "    SGDoptimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=keras.losses.sparse_categorical_crossentropy, \n",
    "        optimizer=SGDoptimizer,\n",
    "        metrics=[keras.metrics.sparse_categorical_accuracy]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_wrapper = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Los valores comentados son los que yo usaría, sin embargo, los he simplificado para reducir el tiempo de entrenamiento. Lo más importante es que se entienda la intención.\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [1,2, 3, 4, 5, 6],\n",
    "    # Probamos de 50 en 50.\n",
    "    \"n_neurons\": np.arange(50, 650, 50),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_wrapper, param_distribs, n_iter=20, cv=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bajamos el número de epochs de patience para que no se alargue el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_cb_unpatient = keras.callbacks.EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[es_cb_unpatient])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_params_\n",
    "# {'learning_rate': 0.01665249551851483, 'n_hidden': 1, 'n_neurons': 200}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-entrenamos con los parámetros óptimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = 1\n",
    "hidden_neurons = 200\n",
    "LR = 0.01665249551851483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt = build_model(n_hidden=hidden_layers, \n",
    "                        n_neurons=hidden_neurons, \n",
    "                        learning_rate=LR, \n",
    "                        input_shape=[28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=LR),\n",
    "              metrics=[keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_ck_cb = keras.callbacks.ModelCheckpoint(\"opt_model.h5\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_opt = model_opt.fit( X_train, y_train, epochs=150, validation_data=(X_valid, y_valid), callbacks=[tb_cb, opt_ck_cb, es_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a ver las gráficas de TB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./tb_logs --port=6008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluamos los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo con 4 capas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_eval = model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0.07861688811050262, 0.9761]\n",
    "print(model_1_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo optimizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt_eval = model_opt.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0.06433085899604485, 0.9808]\n",
    "print(model_opt_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
